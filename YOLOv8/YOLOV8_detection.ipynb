{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36bfebaf-0b62-4a6e-8668-fc7f789a3a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (8.3.153)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: Pillow in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (9.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: albumentations in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (1.4.18)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (1.24.4)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.4.1+cpu)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (0.19.1+cpu)\n",
      "Requirement already satisfied: psutil in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from albumentations) (0.21.0)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from albumentations) (2.10.6)\n",
      "Requirement already satisfied: albucore==0.0.17 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from albumentations) (0.0.17)\n",
      "Requirement already satisfied: eval-type-backport in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from albumentations) (0.2.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from albumentations) (4.13.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics matplotlib opencv-python Pillow tqdm albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866c2ef-1f1e-47cd-8fd5-15cb2841707d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1339631-6218-4aa8-9f4f-f06d0a746ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA διαθέσιμη: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA διαθέσιμη:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"NO GPU\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05ff585-4058-4536-b060-297070055cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation completed.\n",
      "Ultralytics 8.3.153  Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset_yolo\\dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=exp18, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\train\\exp18, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1.42.5 MB/s, size: 3.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\alexi\\dataset_yolo\\labels\\train.cache... 942 images, 0 backgrounds, 0 corrupt: 100%|██████████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2.32.2 MB/s, size: 3.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\alexi\\dataset_yolo\\labels\\val.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\train\\exp18\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp18\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50     0.402G      2.168      2.386      1.157         15        256: 100%|██████████| 59/59 [00:09<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118    0.00542      0.975     0.0442     0.0227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50     0.455G      1.716       1.25       1.01         16        256: 100%|██████████| 59/59 [00:06<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.923      0.607      0.786      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50     0.455G      1.648      1.085      0.978         20        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118       0.86      0.729      0.817      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50     0.455G      1.689      1.015      1.005         19        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.858      0.847      0.874      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50     0.455G      1.556     0.9291     0.9719         21        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.807      0.851      0.853      0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50     0.455G       1.53     0.8616     0.9698         25        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.928      0.872      0.922      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50     0.455G      1.511     0.8646     0.9564         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.943      0.838      0.907      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50     0.455G      1.471     0.7946     0.9495         17        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.954      0.876      0.941      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50     0.455G      1.432     0.7843       0.95         16        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.913      0.796      0.904      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50     0.455G      1.469     0.7741     0.9407         18        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.919      0.864      0.924      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50     0.455G      1.494     0.7958     0.9474         24        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.845      0.881      0.919      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50     0.455G      1.455     0.7733     0.9508         18        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.892      0.909      0.948      0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50     0.455G      1.463     0.7858     0.9533         24        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.956      0.898       0.95       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50     0.455G      1.446     0.7577     0.9424         20        256: 100%|██████████| 59/59 [00:05<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.939      0.898      0.945      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50     0.455G      1.381     0.7238      0.935         21        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.958      0.831      0.927      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50     0.455G      1.372     0.7155     0.9242         22        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118       0.95      0.907      0.963      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50     0.455G      1.313     0.6973     0.9134         18        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.961       0.89      0.946      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50     0.455G      1.343     0.6964      0.915         23        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.924      0.934      0.969      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50     0.455G      1.415     0.7142     0.9422         16        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.963      0.889      0.952      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50     0.455G       1.39     0.7332     0.9361         19        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.974      0.881      0.948      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50     0.455G      1.333     0.6904     0.9279         18        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.946      0.898      0.937      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50     0.455G      1.381     0.7217     0.9342         23        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.918       0.86      0.924      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50     0.455G      1.347     0.6936     0.9181         22        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.959      0.924      0.961      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50     0.455G      1.328     0.6872     0.9122         13        256: 100%|██████████| 59/59 [00:05<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.946      0.899      0.965      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50     0.455G      1.325     0.6892     0.9199         21        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.937      0.886      0.932      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50     0.455G      1.351     0.6867     0.9218         20        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.967      0.864      0.953      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50     0.455G      1.342     0.6906      0.915         24        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.945      0.866      0.943      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50     0.455G       1.32     0.6854     0.9141         16        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.931      0.918      0.952      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50     0.455G      1.291     0.6708     0.9008         16        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.943      0.873      0.937      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50     0.455G       1.29     0.6645     0.9041         22        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.953      0.855      0.929      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50     0.455G        1.3     0.6473     0.9149         24        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.963      0.885      0.942       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50     0.457G      1.303     0.6601     0.9052         23        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.955      0.915      0.961       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50     0.457G      1.255     0.6446     0.9017         18        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.937      0.915      0.952      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50     0.457G      1.241     0.6312     0.8993         20        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.933       0.89      0.957        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50     0.457G      1.285     0.6441     0.8974         23        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118       0.95      0.907      0.951      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50     0.457G      1.259     0.6412     0.9058         20        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.956      0.918      0.962      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50     0.457G      1.249     0.6447     0.9048         18        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118          1      0.922      0.972      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50     0.457G      1.222     0.6164     0.8954         25        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118       0.93      0.895       0.95      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50     0.457G      1.217     0.6161     0.8907         17        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.923      0.898      0.948      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50     0.457G      1.221     0.6225      0.902         17        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.942      0.932      0.949      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50     0.457G      1.165     0.5918     0.9022         14        256: 100%|██████████| 59/59 [00:05<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.957      0.933      0.974      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50     0.457G      1.131     0.5755     0.8946         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.978      0.924      0.972      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50     0.457G      1.124     0.5655     0.8928         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.961      0.915      0.967      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50     0.457G      1.109     0.5546     0.8918         14        256: 100%|██████████| 59/59 [00:05<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118       0.97      0.932      0.972      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50     0.457G      1.098     0.5466      0.879         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.964       0.92      0.961      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50     0.457G      1.092     0.5474     0.8734         14        256: 100%|██████████| 59/59 [00:05<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.982      0.948      0.978      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50     0.457G      1.079     0.5395     0.8825         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.961      0.949      0.977      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50     0.457G      1.065     0.5258     0.8843         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.964       0.92      0.965      0.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50     0.457G      1.081     0.5197     0.8901         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.982      0.937      0.976      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50     0.457G      1.083     0.5199     0.8846         14        256: 100%|██████████| 59/59 [00:05<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.981      0.941      0.974      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.097 hours.\n",
      "Optimizer stripped from runs\\train\\exp18\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\train\\exp18\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\train\\exp18\\weights\\best.pt...\n",
      "Ultralytics 8.3.153  Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        118      0.964      0.914      0.965      0.676\n",
      "Speed: 0.2ms preprocess, 1.5ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\train\\exp18\u001b[0m\n",
      "Evaluating on NAC test set...\n",
      "Ultralytics 8.3.153  Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2.02.0 MB/s, size: 5.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\alexi\\dataset_yolo\\labels\\test\\nac... 59 images, 0 backgrounds, 0 corrupt: 100%|██████████| 59/5\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\alexi\\dataset_yolo\\labels\\test\\nac.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         59      0.914        0.9      0.932      0.622\n",
      "Speed: 0.7ms preprocess, 5.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\train\\exp182\u001b[0m\n",
      "Evaluating on Generated test set...\n",
      "Ultralytics 8.3.153  Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1.51.7 MB/s, size: 2.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\alexi\\dataset_yolo\\labels\\test\\gen... 59 images, 0 backgrounds, 0 corrupt: 100%|██████████| 59/5\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\alexi\\dataset_yolo\\labels\\test\\gen.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         59         59      0.963      0.966      0.991      0.747\n",
      "Speed: 0.9ms preprocess, 4.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\train\\exp183\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "YOLOv8 Dataset Preparation and Fine-Tuning Script\n",
    "\n",
    "This script:\n",
    "1. Reads original NAC bounding-box labels (pixel coords: x1 y1 x2 y2) for 199x199 images.\n",
    "2. Converts and normalizes labels for both NAC (199x199) and Generated (256x256) images into YOLO format.\n",
    "3. Splits data into train/val (combined NAC+Generated) and test (separate NAC and Generated).\n",
    "4. Organizes files into YOLOv8-compatible directory structure.\n",
    "5. Generates a `dataset.yaml` for training and validation.\n",
    "6. Fine-tunes a YOLOv8 model and evaluates on NAC and Generated test sets separately.\n",
    "\n",
    "Requirements:\n",
    "- Python 3.7+\n",
    "- ultralytics (YOLOv8)\n",
    "- scikit-learn\n",
    "- PyYAML\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "# 1. User-configurable paths and parameters\n",
    "orig_img_dir    = Path(r\"C:\\Users\\alexi\\Downloads\\training_yolo_1_source\\NAC\")\n",
    "orig_label_dir  = Path(r\"C:\\Users\\alexi\\Downloads\\training_yolo_1_source\\nac_bb\")\n",
    "gen_img_dir     = Path(r\"C:\\Users\\alexi\\Downloads\\generated\")\n",
    "\n",
    "# Output directories\n",
    "proc_label_dir  = Path(\"processed_labels\")\n",
    "dataset_dir     = Path(\"dataset_yolo\")\n",
    "\n",
    "# Split ratios\n",
    "test_ratio_nac  = 0.1   # 10% of NAC for test only\n",
    "test_ratio_gen  = 0.1   # 10% of Generated for test only\n",
    "train_ratio     = 0.8\n",
    "val_ratio       = 0.1\n",
    "\n",
    "# Image sizes\n",
    "gorig_size      = (199, 199)\n",
    "target_nac_size = (256, 256)\n",
    "target_gen_size = (256, 256)\n",
    "\n",
    "# Ensure processed labels dirs exist\n",
    "for subset in [\"nac\", \"gen\"]:\n",
    "    (proc_label_dir / subset).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Label conversion function\n",
    "\n",
    "def convert_and_save_label(src_path: Path, dst_path: Path, orig_size: tuple, target_size: tuple):\n",
    "    \"\"\"\n",
    "    Read pixel bbox coords (x1, y1, x2, y2) for an image of size orig_size,\n",
    "    scale to target_size, convert to YOLO normalized (class 0).\n",
    "    \"\"\"\n",
    "    with src_path.open('r') as f:\n",
    "        lines = f.read().strip().splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    ow, oh = orig_size\n",
    "    tw, th = target_size\n",
    "    sx, sy = tw/ow, th/oh\n",
    "    with dst_path.open('w') as f:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = map(float, line.split())\n",
    "            # scale coords if needed\n",
    "            x1_s, y1_s = x1*sx, y1*sy\n",
    "            x2_s, y2_s = x2*sx, y2*sy\n",
    "            # YOLO format\n",
    "            xc = (x1_s + x2_s) / 2.0\n",
    "            yc = (y1_s + y2_s) / 2.0\n",
    "            w  = x2_s - x1_s\n",
    "            h  = y2_s - y1_s\n",
    "            # normalize\n",
    "            xc_n = xc / tw\n",
    "            yc_n = yc / th\n",
    "            w_n  = w  / tw\n",
    "            h_n  = h  / th\n",
    "            f.write(f\"0 {xc_n:.6f} {yc_n:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
    "\n",
    "# 3. Process NAC labels\n",
    "for img_path in orig_img_dir.glob(\"*.png\"):\n",
    "    base = img_path.stem\n",
    "    src_label = orig_label_dir / f\"{base}.txt\"\n",
    "    dst_label = proc_label_dir / \"nac\" / f\"{base}.txt\"\n",
    "    if src_label.exists():\n",
    "        convert_and_save_label(src_label, dst_label, orig_size=gorig_size, target_size=target_nac_size)\n",
    "    else:\n",
    "        print(f\"Warning: NAC label for {base} not found.\")\n",
    "\n",
    "# 4. Process Generated labels\n",
    "for img_path in gen_img_dir.glob(\"*_GEN.png\"):\n",
    "    base_gen = img_path.stem        # e.g. img_1_GEN\n",
    "    base     = base_gen.replace(\"_GEN\", \"\")\n",
    "    src_label = orig_label_dir / f\"{base}.txt\"\n",
    "    dst_label = proc_label_dir / \"gen\" / f\"{base_gen}.txt\"\n",
    "    if src_label.exists():\n",
    "        convert_and_save_label(src_label, dst_label, orig_size=gorig_size, target_size=target_gen_size)\n",
    "    else:\n",
    "        print(f\"Warning: NAC label for generated {base_gen} not found.\")\n",
    "\n",
    "# 5. Gather image-label pairs\n",
    "nac_images = list(orig_img_dir.glob(\"*.png\"))\n",
    "gen_images = list(gen_img_dir.glob(\"*_GEN.png\"))\n",
    "\n",
    "nac_pairs = [(img, proc_label_dir / \"nac\" / f\"{img.stem}.txt\") for img in nac_images]\n",
    "gen_pairs = [(img, proc_label_dir / \"gen\" / f\"{img.stem}.txt\") for img in gen_images]\n",
    "# Filter only existing labels\n",
    "nac_pairs = [(i,l) for i,l in nac_pairs if l.exists()]\n",
    "gen_pairs = [(i,l) for i,l in gen_pairs if l.exists()]\n",
    "\n",
    "# 6. Split into train/val and test\n",
    "nac_train_val, nac_test = train_test_split(nac_pairs, test_size=test_ratio_nac, random_state=42)\n",
    "gen_train_val, gen_test = train_test_split(gen_pairs, test_size=test_ratio_gen, random_state=42)\n",
    "\n",
    "# Combine for train/val\n",
    "train_val = nac_train_val + gen_train_val\n",
    "val_fraction = val_ratio / (train_ratio + val_ratio)\n",
    "train_pairs, val_pairs = train_test_split(train_val, test_size=val_fraction, random_state=42)\n",
    "\n",
    "# 7. Create YOLOv8 directory structure\n",
    "for split in [\"train\", \"val\"]:\n",
    "    (dataset_dir / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    (dataset_dir / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "# test splits\n",
    "(dataset_dir / \"images\" / \"test\" / \"nac\").mkdir(parents=True, exist_ok=True)\n",
    "(dataset_dir / \"labels\" / \"test\" / \"nac\").mkdir(parents=True, exist_ok=True)\n",
    "(dataset_dir / \"images\" / \"test\" / \"gen\").mkdir(parents=True, exist_ok=True)\n",
    "(dataset_dir / \"labels\" / \"test\" / \"gen\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 8. Copy files into structure\n",
    "def copy_set(pairs, split, prefix=\"\"):\n",
    "    for img, lbl in pairs:\n",
    "        out_img = dataset_dir / \"images\"\n",
    "        out_lbl = dataset_dir / \"labels\"\n",
    "        if split in [\"train\",\"val\"]:\n",
    "            out_img = out_img / split / img.name\n",
    "            out_lbl = out_lbl / split / lbl.name\n",
    "        else:\n",
    "            # split is a tuple (\"test/nac\" or \"test/gen\")\n",
    "            kind = split.split('/')[1]\n",
    "            out_img = out_img / \"test\" / kind / img.name\n",
    "            out_lbl = out_lbl / \"test\" / kind / lbl.name\n",
    "        shutil.copy(img, out_img)\n",
    "        shutil.copy(lbl, out_lbl)\n",
    "\n",
    "copy_set(train_pairs, \"train\")\n",
    "copy_set(val_pairs,   \"val\")\n",
    "copy_set(nac_test,   \"test/nac\")\n",
    "copy_set(gen_test,   \"test/gen\")\n",
    "\n",
    "# 9. Write dataset.yaml\n",
    "with open(dataset_dir / 'dataset.yaml', 'w') as f:\n",
    "    yaml.dump({\n",
    "        'path': str(dataset_dir),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': 1,\n",
    "        'names': ['nac']\n",
    "    }, f)\n",
    "\n",
    "print(\"Dataset preparation completed.\")\n",
    "\n",
    "# 10. Fine-tune YOLOv8 and evaluate\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    model.train(\n",
    "        data=str(dataset_dir / 'dataset.yaml'),\n",
    "        epochs=50,\n",
    "        imgsz=256,\n",
    "        project='runs/train',\n",
    "        name='exp1'\n",
    "    )\n",
    "\n",
    "    # NAC test set evaluation\n",
    "    nac_test_yaml_path = dataset_dir / 'nac_test.yaml'\n",
    "    with open(nac_test_yaml_path, 'w') as f:\n",
    "        yaml.dump({\n",
    "            'path': str(dataset_dir),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/test/nac',\n",
    "            'nc': 1,\n",
    "            'names': ['nac']\n",
    "        }, f)\n",
    "\n",
    "    print(\"Evaluating on NAC test set...\")\n",
    "    model.val(data=str(nac_test_yaml_path), imgsz=256)\n",
    "\n",
    "    # Generated test set evaluation\n",
    "    gen_test_yaml_path = dataset_dir / 'gen_test.yaml'\n",
    "    with open(gen_test_yaml_path, 'w') as f:\n",
    "        yaml.dump({\n",
    "            'path': str(dataset_dir),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/test/gen',\n",
    "            'nc': 1,\n",
    "            'names': ['nac']\n",
    "        }, f)\n",
    "\n",
    "    print(\"Evaluating on Generated test set...\")\n",
    "    model.val(data=str(gen_test_yaml_path), imgsz=256)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Please install ultralytics (`pip install ultralytics`) to train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b25b943-b1b8-41bf-837d-20062e1aad01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain/Val\u001b[39m\u001b[38;5;124m'\u001b[39m: val_values,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAC Test\u001b[39m\u001b[38;5;124m'\u001b[39m: nac_values,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerated Test\u001b[39m\u001b[38;5;124m'\u001b[39m: gen_values\n\u001b[0;32m     21\u001b[0m })\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Εμφάνιση πίνακα\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m; tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOLOv8 Full Metrics Comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Δημιουργία γραφήματος\u001b[39;00m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(metrics))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Νέα δεδομένα από το τελευταίο run\n",
    "metrics = ['Precision', 'Recall', 'mAP50', 'mAP50-95']\n",
    "\n",
    "# Αποτελέσματα από validation set (εκπαίδευση)\n",
    "val_values = [0.964, 0.914, 0.965, 0.676]\n",
    "# Αποτελέσματα από NAC test set\n",
    "nac_values = [0.914, 0.900, 0.932, 0.622]\n",
    "# Αποτελέσματα από Generated test set\n",
    "gen_values = [0.963, 0.966, 0.991, 0.747]\n",
    "\n",
    "# Δημιουργία DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Train/Val': val_values,\n",
    "    'NAC Test': nac_values,\n",
    "    'Generated Test': gen_values\n",
    "})\n",
    "\n",
    "# Εμφάνιση πίνακα\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"YOLOv8 Full Metrics Comparison\", dataframe=df)\n",
    "\n",
    "# Δημιουργία γραφήματος\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width, df['Train/Val'], width, label='Train/Val')\n",
    "bars2 = ax.bar(x, df['NAC Test'], width, label='NAC Test')\n",
    "bars3 = ax.bar(x + width, df['Generated Test'], width, label='Generated Test')\n",
    "\n",
    "ax.set_ylabel('Metric Value')\n",
    "ax.set_title('YOLOv8 Metrics Comparison (Train/Val vs NAC vs Generated)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Εμφάνιση τιμών πάνω από τις μπάρες\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee405d-cc6b-4db1-b531-060edf891694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'comparison_metrics.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create DataFrame with the final evaluation metrics\n",
    "data = {\n",
    "    'Metric': ['Precision', 'Recall', 'mAP50', 'mAP50-95'],\n",
    "    'Train/Val': [0.964, 0.914, 0.965, 0.676],\n",
    "    'NAC Test': [0.914, 0.900, 0.932, 0.622],\n",
    "    'Generated Test': [0.963, 0.966, 0.991, 0.747]\n",
    "}\n",
    "df_metrics = pd.DataFrame(data)\n",
    "\n",
    "# Calculate percentage difference between Generated and NAC Test\n",
    "df_metrics['% Difference (Gen - NAC)'] = 100 * (\n",
    "    df_metrics['Generated Test'] - df_metrics['NAC Test']\n",
    ") / df_metrics['NAC Test']\n",
    "\n",
    "# Save comparison metrics to CSV file\n",
    "csv_path = \"comparison_metrics.csv\"\n",
    "df_metrics.to_csv(csv_path, index=False)\n",
    "\n",
    "# Plot percentage improvements of Generated over NAC Test\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(\n",
    "    df_metrics['Metric'],\n",
    "    df_metrics['% Difference (Gen - NAC)']\n",
    ")\n",
    "ax.set_title(\"Percentage Improvement of Generated vs NAC Test\")\n",
    "ax.set_ylabel(\"Difference (%)\")\n",
    "ax.axhline(0, color='gray', linewidth=0.8)\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Annotate each bar with its corresponding value\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval,\n",
    "        f\"{yval:.1f}%\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Return the CSV path for reference\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cd0fc-3d1a-4b0a-8827-13c12a041775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_100.png: 256x256 1 nac, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_104.png: 256x256 1 nac, 9.8ms\n",
      "Speed: 0.8ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_108.png: 256x256 1 nac, 9.7ms\n",
      "Speed: 0.8ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_102_GEN.png: 256x256 1 nac, 13.5ms\n",
      "Speed: 0.8ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_106_GEN.png: 256x256 1 nac, 10.1ms\n",
      "Speed: 0.8ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_10_GEN.png: 256x256 1 nac, 10.9ms\n",
      "Speed: 0.7ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "from ultralytics import YOLO\n",
    "model_path = \"runs/train/exp18/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Directories containing test images\n",
    "nac_test_dir = Path(\"dataset_yolo/images/test/nac\")\n",
    "gen_test_dir = Path(\"dataset_yolo/images/test/gen\")\n",
    "\n",
    "# Select 3 sample images from each set\n",
    "nac_samples = sorted(glob(str(nac_test_dir / \"*.png\")))[:3]\n",
    "gen_samples = sorted(glob(str(gen_test_dir / \"*.png\")))[:3]\n",
    "\n",
    "# Function to run predictions and display results\n",
    "def show_predictions(image_paths, title_prefix):\n",
    "    fig, axs = plt.subplots(1, len(image_paths), figsize=(15, 5))\n",
    "    if len(image_paths) == 1:\n",
    "        axs = [axs]\n",
    "    for ax, img_path in zip(axs, image_paths):\n",
    "        # Run inference on a single image\n",
    "        results = model(img_path)[0]\n",
    "        # Load and convert image for plotting\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Draw bounding boxes and confidence scores\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = box.conf[0].cpu().numpy()\n",
    "            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(img, f'{conf:.2f}', (int(x1), int(y1)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"{title_prefix} Sample\")\n",
    "    plt.suptitle(f\"{title_prefix} Predictions\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display predictions for NAC and generated images\n",
    "show_predictions(nac_samples, \"NAC\")\n",
    "show_predictions(gen_samples, \"Generated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1555ab-e4d9-4861-9382-431faaaa0d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (8.3.153)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.4.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (0.19.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\alexi\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed011b-49fa-4ea2-bb49-dec6993112a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_100.png: 256x256 1 nac, 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 148.1ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_104.png: 256x256 1 nac, 11.8ms\n",
      "Speed: 0.9ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_108.png: 256x256 1 nac, 10.6ms\n",
      "Speed: 0.8ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_102_GEN.png: 256x256 1 nac, 12.4ms\n",
      "Speed: 0.7ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_106_GEN.png: 256x256 1 nac, 10.3ms\n",
      "Speed: 0.9ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_10_GEN.png: 256x256 1 nac, 10.7ms\n",
      "Speed: 0.8ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('Yolo_Prediction')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create export directory and subdirectories\n",
    "export_dir = Path(\"Yolo_Prediction\")\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare and save summary metrics to CSV\n",
    "metrics = ['Precision', 'Recall', 'mAP50', 'mAP50-95']\n",
    "val_values = [0.964, 0.914, 0.965, 0.676]\n",
    "nac_values = [0.914, 0.900, 0.932, 0.622]\n",
    "gen_values = [0.963, 0.966, 0.991, 0.747]\n",
    "\n",
    "df_metrics = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Train/Val': val_values,\n",
    "    'NAC Test': nac_values,\n",
    "    'Generated Test': gen_values\n",
    "})\n",
    "# Compute percentage difference between generated and NAC tests\n",
    "df_metrics['% Difference (Gen - NAC)'] = 100 * (\n",
    "    df_metrics['Generated Test'] - df_metrics['NAC Test']\n",
    ") / df_metrics['NAC Test']\n",
    "\n",
    "csv_out = export_dir / \"comparison_metrics.csv\"\n",
    "df_metrics.to_csv(csv_out, index=False)\n",
    "\n",
    "# Plot and save bar chart comparing metrics across datasets\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "bars1 = ax.bar(x - width, val_values, width, label='Train/Val')\n",
    "bars2 = ax.bar(x, nac_values, width, label='NAC Test')\n",
    "bars3 = ax.bar(x + width, gen_values, width, label='Generated Test')\n",
    "ax.set_ylabel('Metric Value')\n",
    "ax.set_title('YOLOv8 Metrics Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Annotate bars with values\n",
    "def annotate_bars(bar_container):\n",
    "    for bar in bar_container:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height,\n",
    "            f'{height:.2f}',\n",
    "            ha='center', va='bottom'\n",
    "        )\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    annotate_bars(bars)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(export_dir / \"metrics_comparison_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot and save improvement over NAC for generated images\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(df_metrics['Metric'], df_metrics['% Difference (Gen - NAC)'])\n",
    "ax.set_title(\"Improvement (%) of Generated vs NAC\")\n",
    "ax.set_ylabel(\"Difference (%)\")\n",
    "ax.axhline(0, color='gray', linewidth=0.8)\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval,\n",
    "        f\"{yval:.1f}%\",\n",
    "        ha='center', va='bottom'\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.savefig(export_dir / \"improvement_generated_vs_nac.png\")\n",
    "plt.close()\n",
    "\n",
    "# Create folder for saving sample predictions\n",
    "img_out_dir = export_dir / \"sample_predictions\"\n",
    "img_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO(\"runs/train/exp18/weights/best.pt\")\n",
    "\n",
    "# Define test image directories and select samples\n",
    "nac_test_dir = Path(\"dataset_yolo/images/test/nac\")\n",
    "gen_test_dir = Path(\"dataset_yolo/images/test/gen\")\n",
    "nac_samples = sorted(nac_test_dir.glob(\"*.png\"))[:3]\n",
    "gen_samples = sorted(gen_test_dir.glob(\"*.png\"))[:3]\n",
    "\n",
    "# Function to save model predictions on images\n",
    "def save_predictions(image_paths, prefix):\n",
    "    for img_path in image_paths:\n",
    "        results = model(str(img_path))[0]\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Draw bounding boxes and confidence scores\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = box.conf[0].cpu().numpy()\n",
    "            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                img,\n",
    "                f'{conf:.2f}',\n",
    "                (int(x1), int(y1) - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                1\n",
    "            )\n",
    "        out_path = img_out_dir / f\"{prefix}_{img_path.name}\"\n",
    "        cv2.imwrite(str(out_path), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Save predictions for both NAC and generated samples\n",
    "save_predictions(nac_samples, \"NAC\")\n",
    "save_predictions(gen_samples, \"GEN\")\n",
    "\n",
    "# Return export directory path\n",
    "export_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe835401-27d8-44ee-a96b-e9815d514126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📷 Προβολή προβλέψεων για: NAC\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_164.png: 256x256 1 nac, 9.9ms\n",
      "Speed: 1.1ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\nac\\img_326.png: 256x256 1 nac, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📷 Προβολή προβλέψεων για: GEN\n",
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_164_GEN.png: 256x256 1 nac, 10.0ms\n",
      "Speed: 1.3ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAAEX0lEQVR4nO3c21MbVRgA8OxuEiClUAq03MEWqta21lb7UsfLg5dxfPfP89Xxz9DxMo46zuiMjg6l04ZGLqVcwiWQsD7QRiqFJrQlG/n9eNmwZ5dv4PvOObvnDKl0FKXgWEpH6UaHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8ERBowMgYeLHPx6QIPE+3w/2aSDXSLq9Ob1flj/18njPqbpudVTCRgfA8ZDU7j/d6AB4mvhR9lR70L3JtLtzDWo+9XzFyc3yAxgBmsROej0xw2o59Sypmcipy/OiAJrBfzrXeJ9Te/v+A0aDGtVYOc3Z/adMgZpD8PhxNY/rSrsjTtCgOYYOBcCBaqmx/do8+/jz4pkCAUl28Lv5va/ba7ywlh9Xyx32u+cBgSWJKVDzO2BF9nBrsTXm9KHvAwAAAAAAcBSacwvfMVHXQpK/5KHYC5RUll2PhALgWLMXKOmybdn23KlMtvzO+x8vPJgfHhjIdfR29bT//NMPhcn5yanfV5aXGx1jE1MASRQEQfxoTnP18uXLb1wZGui/NPbWcrkQx9H84v2hoXNjE8O3fp365sfsV6mvGxttU1MASRRFUTlV3jl+/frFt29+0j/cdbbrzIPlrr9nCq2tmeJSqbwyF1TCmxffqxZAEARx7FGgPp4Bkm7s5aun+rpXFouLc0tRJdPf29/XOVreWM3PLm+sbl5789VqyyiKgsDLoPoYARInCILdI0BX7tTS7Gwl2CqurE0XZvvH+8rFpWK0ulBcGBsc7Ro4Xb0wDKNKpdKgqJuVAkiiTDZTSpV2jleK69ulxc219fliWAkXOvIrY2cunWg/e/K11sGRoXu3plPvPrwq29JSLm+ZBdVFASTR7hzuycVR+8nPv/yish4NvzL6y3dTH37akuluH7kwvlRY/uv2ZLVlOhumVhsQbVNTAIkTx/FmqVT92DMymo4qH3z02dSdP+cL+bAlmpmeie7NLI1Wbpwfy092VlturG82It7mpgCSaPdU/vtvf+vt6ejMrg+dn2jrzmTvpwe7z96Zmxsoh4tbnYODZ6ott0ol8596eQuURNvb29Xj29N/5Ofvrmfb2pbDa5dutHX35jpy4y/1dXekWltWRiaGGhjn/4ARIOnm8nf7T5wupTfOjfd15qLT16+sdW61rbXlcidGOrrubdyvttzW/ddPASRdYXruwng4NDy4UQm2FqPWzHa4USlnN1ejSiEK8/m5f5vGsSlQvaybJNWL+0e27OIZgGNNASRVvd257v9Q/NqaSRAEcZza2e/zcOvbzhcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQGMEYdDoEKAxgjD4B24iJ1GZJww8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\alexi\\dataset_yolo\\images\\test\\gen\\img_326_GEN.png: 256x256 1 nac, 10.3ms\n",
      "Speed: 0.9ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Dataset'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m             df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{col: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# 7. Bar plot για mAP@50 και mAP@50-95\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@50-95\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     80\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Average Precision Comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages\\pandas\\core\\frame.py:5859\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5856\u001b[0m                 missing\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m   5858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 5859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are in the columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   5862\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Dataset'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "YOLOv8 Evaluation and Reporting Script (Inline Visualization)\n",
    "- Select 2 NAC and corresponding 2 generated images for visual comparison\n",
    "- Run predictions and display annotated images\n",
    "- Show comparative plots and metrics within the notebook\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image as IPImage\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Define dataset paths\n",
    "base_dir = Path(\"dataset_yolo\")\n",
    "nac_test_dir = base_dir / \"images/test/nac\"\n",
    "gen_test_dir = base_dir / \"images/test/gen\"\n",
    "\n",
    "# Load best-trained model\n",
    "model = YOLO(\"runs/train/exp18/weights/best.pt\")  # update path if needed\n",
    "\n",
    "# Collect matching sample pairs (up to 2)\n",
    "nac_samples = []\n",
    "gen_samples = []\n",
    "for img_path in sorted(nac_test_dir.glob(\"*.png\")):\n",
    "    gen_name = f\"{img_path.stem}_GEN.png\"\n",
    "    gen_path = gen_test_dir / gen_name\n",
    "    if gen_path.exists():\n",
    "        nac_samples.append(img_path)\n",
    "        gen_samples.append(gen_path)\n",
    "    if len(nac_samples) == 2:\n",
    "        break\n",
    "\n",
    "# Function to display predictions inline\n",
    "def show_predictions(image_paths, prefix):\n",
    "    print(f\"\\nDisplaying predictions for: {prefix}\")\n",
    "    for img_path in image_paths:\n",
    "        results = model(str(img_path))[0]\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Warning: Image not found at {img_path}\")\n",
    "            continue\n",
    "        # Draw bounding boxes and labels\n",
    "        for box in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, cls = box\n",
    "            coords = map(int, (x1, y1, x2, y2))\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                img,\n",
    "                f\"{model.names[int(cls)]} {score:.2f}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                1\n",
    "            )\n",
    "        # Convert to RGB for display\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        buf = io.BytesIO()\n",
    "        pil_img.save(buf, format='PNG')\n",
    "        display(IPImage(data=buf.getvalue()))\n",
    "\n",
    "# Display predictions for both sets\n",
    "show_predictions(nac_samples, \"NAC\")\n",
    "show_predictions(gen_samples, \"Generated\")\n",
    "\n",
    "# Load metrics CSV if available\n",
    "metrics_csv = Path(\"comparison_metrics.csv\")\n",
    "if metrics_csv.exists():\n",
    "    df = pd.read_csv(metrics_csv)\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    # Normalize dataset column name\n",
    "    if 'Dataset' not in df.columns:\n",
    "        for col in df.columns:\n",
    "            if 'test' in col.lower() or 'train' in col.lower():\n",
    "                df.rename(columns={col: 'Dataset'}, inplace=True)\n",
    "    # Plot mAP50 and mAP50-95 comparisons\n",
    "    df.set_index(\"Dataset\")[['mAP@50', 'mAP@50-95']].plot(\n",
    "        kind='bar', figsize=(10, 6)\n",
    "    )\n",
    "    plt.title(\"Mean Average Precision Comparison\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Precision and Recall\n",
    "    df.set_index(\"Dataset\")[['Precision', 'Recall']].plot(\n",
    "        kind='bar', figsize=(10, 6)\n",
    "    )\n",
    "    plt.title(\"Precision and Recall Comparison\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Comparison metrics file not found: 'comparison_metrics.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d831e-21cb-4540-813c-ec99d85e1097",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Dataset'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Bar Plot για mAP metrics\u001b[39;00m\n\u001b[0;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m---> 29\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@50-95\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmAP Comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.05\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\graph_parser_env\\lib\\site-packages\\pandas\\core\\frame.py:5859\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5856\u001b[0m                 missing\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m   5858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 5859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are in the columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   5862\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Dataset'] are in the columns\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "YOLOv8 Results Export Script\n",
    "- Load evaluation metrics and save bar plots\n",
    "- Run YOLO predictions on 2 NAC-GEN image pairs and save results\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define paths for metrics CSV and output directory\n",
    "metrics_csv = Path(\"comparison_metrics.csv\")\n",
    "results_dir = Path(\"yolo_results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Load metrics and generate comparison plots\n",
    "if metrics_csv.exists():\n",
    "    df = pd.read_csv(metrics_csv)\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    # Rename dataset column if necessary\n",
    "    if 'Dataset' not in df.columns:\n",
    "        detected = [c for c in df.columns if 'set' in c.lower()]\n",
    "        if detected:\n",
    "            df.rename(columns={detected[0]: 'Dataset'}, inplace=True)\n",
    "\n",
    "    # Plot mAP@50 and mAP@50-95\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df.set_index('Dataset')[['mAP@50', 'mAP@50-95']].plot(kind='bar', title='mAP Comparison')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'map_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Precision and Recall\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df.set_index('Dataset')[['Precision', 'Recall']] \\\n",
    "      .plot(kind='bar', color=['orange', 'green'], title='Precision & Recall')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'precision_recall_comparison.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"⚠️  Metrics file not found: comparison_metrics.csv\")\n",
    "\n",
    "# 2. Prepare YOLO model and sample image pairs\n",
    "model = YOLO('runs/train/exp18/weights/best.pt')  # update path if needed\n",
    "\n",
    "nac_dir = Path('dataset_yolo/images/test/nac')\n",
    "gen_dir = Path('dataset_yolo/images/test/gen')\n",
    "\n",
    "nac_samples, gen_samples = [], []\n",
    "for img in sorted(nac_dir.glob('*.png')):\n",
    "    pair = gen_dir / f\"{img.stem}_GEN.png\"\n",
    "    if pair.exists():\n",
    "        nac_samples.append(img)\n",
    "        gen_samples.append(pair)\n",
    "    if len(nac_samples) == 2:\n",
    "        break\n",
    "\n",
    "# 3. Function to save YOLO predictions on an image\n",
    "\n",
    "def save_yolo_prediction(img_path, model, save_path):\n",
    "    results = model(str(img_path))[0]\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"Warning: Image not found at {img_path}\")\n",
    "        return\n",
    "    # Draw boxes and labels on image\n",
    "    for box in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, cls = box\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        label = f\"{model.names[int(cls)]} {score:.2f}\"\n",
    "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    cv2.imwrite(str(save_path), img)\n",
    "\n",
    "# 4. Save annotated sample images\n",
    "print(\"\\n💾 Saving YOLO predictions to yolo_results folder\")\n",
    "for idx, (nac, gen) in enumerate(zip(nac_samples, gen_samples), start=1):\n",
    "    save_yolo_prediction(nac, model, results_dir / f\"sample_{idx}_NAC.png\")\n",
    "    save_yolo_prediction(gen, model, results_dir / f\"sample_{idx}_GEN.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c009b-8ae3-477d-bc5f-5fa63152f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (graph_parser_env)",
   "language": "python",
   "name": "graph_parser_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
